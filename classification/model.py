import copy
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):

    def __init__(self, args):
        super().__init__()
        ##############################################################################
        #                  TODO: You need to complete the code here                  #
        ##############################################################################
        self.device = args.device
        global tokenizer
        global llm
        # self.path = '/ssdshare/LLMs/MiniCPM-2B-dpo-bf16/'
        tokenizer,llm = self.load_llm()
        # tokenizer.to(self.device)
        llm.to(self.device)
        self.useless = nn.Parameter(torch.zeros(1,requires_grad=True))
        ##############################################################################
        #                              END OF YOUR CODE                              #
        ##############################################################################
    
    def load_llm(self):
        ##############################################################################
        #                  TODO: You need to complete the code here                  #
        ##############################################################################
        import torch
        from tqdm import tqdm
        from transformers import AutoModelForCausalLM, AutoTokenizer
        path = "models/checkpoint/"
        global tokenizer
        global llm
        tokenizer = AutoTokenizer.from_pretrained(path)
        llm = AutoModelForCausalLM.from_pretrained(
            path, torch_dtype=torch.bfloat16, device_map="cuda", trust_remote_code=True
        )
        return tokenizer,llm
        ##############################################################################
        #                              END OF YOUR CODE                              #
        ##############################################################################

    def logits(self, **kwargs):
        """
        Compute the logits for the input data.

        Args:
            kwargs (dict): Custom keyword arguments containing input data.
                          Modify the input processing according to your needs.

        Returns:
            logits (tensor): Logits generated by your model given input.
        """
        # ##############################################################################
        #                  TODO: You need to complete the code here                  #
        ##############################################################################
        def format_choices(r:list[str]):
            out = []
            for i,c in enumerate(r):
                c = c.replace('A','').replace('B','').replace('C','').replace('D','').replace('.','').replace('．','').strip()
                out.append('ABCD'[i]+'. '+c)
            return '|'.join(out)
        def cnt_sentence(s:str):
            def cnt_num(s:str,c:str):
                return len(s.split(c))-1
            return sum([cnt_num(s,c) for c in ['。','！','？']])
        logits = []
        for i in range(len(kwargs['texts'])):
            text = kwargs['texts'][i]
            inputs = f"""文段#{text}*句子个数#共{cnt_sentence(text)}句话*题目#{(kwargs['questions'][i])}*选项#{format_choices(kwargs['choices'][i])}""" 
            # print(inputs)
            if len(inputs) > 1500:
                text = text[:-1-(len(inputs)-1500)]
                inputs = f"""文段#{text}*句子个数#共{cnt_sentence(text)}句话*题目#{(kwargs['questions'][i])}*选项#{format_choices(kwargs['choices'][i])}""" 
            res, history = llm.chat(tokenizer, query=f"<用户>{inputs}<AI>", max_length=1501)
            if len(res)>1:
                open('./log.log','a').write(f'question:\n\n{inputs}\n\nanswer:<{res}>\n\n')
            res=res[0].upper()
            if res in 'ABCD':
                l = [0.001,0.001,0.001,0.001]
                l['ABCD'.index(res)]+=0.996
                logits.append(l.copy())
            else:                
                logits.append([0.28,0.25,0.25,0.25])
        return torch.tensor(logits)
        ##############################################################################
        #                              END OF YOUR CODE                              #
        ##############################################################################

    def get_loss(self, **kwargs):
        """
        Compute the loss for the input data and target labels.

        Args:
            kwargs (dict): Custom keyword arguments containing input data and
                           target labels. Modify the input and target processing
                           according to your needs.

        Returns:
            loss (tensor): The loss for the input data and target labels.
        """
        # ##############################################################################
        #                  TODO: You need to complete the code here                  #
        ##############################################################################
        targets = kwargs['targets']
        logits = self.logits(**kwargs)
        return F.cross_entropy(logits, targets)
        #######################################################`#######################
        #                              END OF YOUR CODE                              #
        ##############################################################################

if __name__ == '__main__':
    class Args:
        device = 'cuda'
    args = Args()
    model = Net(args)
    torch.save(model,'./models/cls_best.pt')