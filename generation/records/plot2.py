transformer_seq2seq = """Epoch: 1, Loss: 2674.70584864, lr: 0.000100: 100%|██████████| 11961/11961 [10:22<00:00, 19.23it/s]
valid: loss: 1.386, ppl: 68.197
Epoch: 2, Loss: 2273.00048200, lr: 0.000100: 100%|██████████| 11961/11961 [09:56<00:00, 20.05it/s]
valid: loss: 1.300, ppl: 55.192
Epoch: 3, Loss: 2145.59195764, lr: 0.000100: 100%|██████████| 11961/11961 [10:04<00:00, 19.78it/s]
valid: loss: 1.259, ppl: 49.911
Epoch: 4, Loss: 2064.89563348, lr: 0.000100: 100%|██████████| 11961/11961 [10:15<00:00, 19.43it/s]
valid: loss: 1.234, ppl: 48.585
Epoch: 5, Loss: 2003.74838370, lr: 0.000100: 100%|██████████| 11961/11961 [10:19<00:00, 19.32it/s]
valid: loss: 1.219, ppl: 47.259
Epoch: 6, Loss: 1955.15772647, lr: 0.000100: 100%|██████████| 11961/11961 [09:56<00:00, 20.06it/s]
valid: loss: 1.208, ppl: 47.063
Epoch: 7, Loss: 1916.38515930, lr: 0.000100: 100%|██████████| 11961/11961 [10:17<00:00, 19.36it/s]
valid: loss: 1.201, ppl: 46.932"""
transformer_lm = """training model at 0430-0956
Epoch: 1, Loss: 11829.08232593, lr: 0.000100: 100%|██████████| 1715/1715 [01:00<00:00, 28.13it/s]
valid: loss: 5.694, ppl: 336.470
Epoch: 2, Loss: 10684.01439533, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 28.07it/s]
valid: loss: 5.197, ppl: 217.923
Epoch: 3, Loss: 9948.09984882, lr: 0.000100: 100%|██████████| 1715/1715 [01:00<00:00, 28.13it/s] 
valid: loss: 4.930, ppl: 172.231
Epoch: 4, Loss: 9485.40053298, lr: 0.000100: 100%|██████████| 1715/1715 [01:00<00:00, 28.12it/s]
valid: loss: 4.760, ppl: 146.374
Epoch: 5, Loss: 9135.61049790, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.85it/s]
valid: loss: 4.616, ppl: 127.974
Epoch: 6, Loss: 8838.72152224, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.87it/s]
valid: loss: 4.507, ppl: 115.120
Epoch: 7, Loss: 8606.33513604, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.87it/s]
valid: loss: 4.432, ppl: 107.106
Epoch: 8, Loss: 8429.04820033, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.99it/s]
valid: loss: 4.374, ppl: 101.218
Epoch: 9, Loss: 8286.15537052, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 28.08it/s]
valid: loss: 4.332, ppl: 96.889
Epoch: 10, Loss: 8161.37389304, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.99it/s]
valid: loss: 4.298, ppl: 94.128
Epoch: 11, Loss: 8052.49948738, lr: 0.000100: 100%|██████████| 1715/1715 [01:00<00:00, 28.29it/s]
valid: loss: 4.266, ppl: 91.432
Epoch: 12, Loss: 7955.37466888, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.99it/s]
valid: loss: 4.253, ppl: 90.918
Epoch: 13, Loss: 7868.04038100, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 28.00it/s]
valid: loss: 4.236, ppl: 89.545
Epoch: 14, Loss: 7783.51250000, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 28.08it/s]
valid: loss: 4.225, ppl: 88.849
Epoch: 15, Loss: 7699.99648295, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.97it/s]
valid: loss: 4.213, ppl: 88.229
Epoch: 16, Loss: 7632.19577601, lr: 0.000100: 100%|██████████| 1715/1715 [01:01<00:00, 27.91it/s]
valid: loss: 4.208, ppl: 88.562
"""
lstm_seq2seq = """training model at 04292004
Epoch: 1, Loss: 3676.82603531, lr: 0.000200: 100%|██████████| 11961/11961 [06:30<00:00, 30.64it/s]
valid: loss: 1.869, ppl: 184.266
Epoch: 2, Loss: 2975.35617482, lr: 0.000200: 100%|██████████| 11961/11961 [06:28<00:00, 30.81it/s]
valid: loss: 1.666, ppl: 127.256
Epoch: 3, Loss: 2714.08414495, lr: 0.000200: 100%|██████████| 11961/11961 [06:25<00:00, 30.99it/s]
valid: loss: 1.551, ppl: 99.402
Epoch: 4, Loss: 2554.02734477, lr: 0.000200: 100%|██████████| 11961/11961 [06:56<00:00, 28.70it/s]
valid: loss: 1.483, ppl: 85.065
Epoch: 5, Loss: 2449.81839221, lr: 0.000200: 100%|██████████| 11961/11961 [06:25<00:00, 31.02it/s]
valid: loss: 1.438, ppl: 77.706
Epoch: 6, Loss: 2375.68164862, lr: 0.000200: 100%|██████████| 11961/11961 [06:25<00:00, 31.00it/s]
valid: loss: 1.409, ppl: 72.984
Epoch: 7, Loss: 2318.70049577, lr: 0.000200: 100%|██████████| 11961/11961 [06:26<00:00, 30.93it/s]
valid: loss: 1.382, ppl: 70.922
Epoch: 8, Loss: 2271.87989242, lr: 0.000200: 100%|██████████| 11961/11961 [06:26<00:00, 30.95it/s]
valid: loss: 1.367, ppl: 67.997
Epoch: 9, Loss: 2232.15031024, lr: 0.000200: 100%|██████████| 11961/11961 [06:26<00:00, 30.93it/s]
valid: loss: 1.358, ppl: 67.426
Epoch: 10, Loss: 2197.16010815, lr: 0.000200: 100%|██████████| 11961/11961 [06:26<00:00, 30.95it/s]
valid: loss: 1.345, ppl: 66.383
Epoch: 11, Loss: 2165.90852982, lr: 0.000200: 100%|██████████| 11961/11961 [06:26<00:00, 30.93it/s]
valid: loss: 1.338, ppl: 65.080
Epoch: 12, Loss: 2136.88241518, lr: 0.000200: 100%|██████████| 11961/11961 [06:27<00:00, 30.88it/s]
valid: loss: 1.334, ppl: 68.458
Epoch: 13, Loss: 2105.67231471, lr: 0.000200:  77%|███████▋  | 9262/11961 [05:00<01:27, 30.86it/s]
"""
from plot import plot
plot(transformer_seq2seq.split('\n'),'./transformer_seq2seq.png')
plot(lstm_seq2seq.split('\n'),'./lstm_seq2seq.png')
plot(transformer_lm.split('\n'),'./transformer_lm.png')
